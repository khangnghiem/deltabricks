{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efad6684-f133-4615-b200-038acf055460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, col, datediff, max as spark_max\n",
    "\n",
    "df = spark.sql(f\"SELECT * FROM dev.job_prospects.job_1900_silver_inferred\")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a48d8475-0a83-442d-bf3b-4f3d89b4bb7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_timestamp = df.agg(spark_max(\"timestamp\").alias(\"max_ts\")).collect()[0][\"max_ts\"]\n",
    "\n",
    "last_7_days_df = df.filter(\n",
    "    (col(\"timestamp\") == max_timestamp)\n",
    "    & (datediff(current_date(), col(\"posted_at\")) <= 7)\n",
    ")\n",
    "\n",
    "last_30_days_df = df.filter(\n",
    "    (col(\"timestamp\") == max_timestamp)\n",
    "    & (datediff(current_date(), col(\"posted_at\")) <= 30)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51df6ef-4596-4cb6-90cf-6ed3cf790f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_top_10_job_last_7_days = last_7_days_df.groupBy(\"job_field\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "df_top_10_job_last_30_days = last_30_days_df.groupBy(\"job_field\").count().orderBy(col(\"count\").desc()).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd590ad-f9c6-48dd-a139-898b6d67c3fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_top_10_job_last_7_days.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"dev.job_prospects.fct_top_10_last_week\")\n",
    "df_top_10_job_last_30_days.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"dev.job_prospects.fct_top_10_last_month\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "top_recent_jobs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

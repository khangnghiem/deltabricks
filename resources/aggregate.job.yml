# The main job for deltabricks.
resources:
  jobs:
    aggregate_job_prospects:
      name: aggregate_job_prospects
      trigger:
        periodic:
          interval: 7
          unit: DAYS
      #email_notifications:
      #  on_failure:
      #    - khangnghiem@gmail.com

      tasks:
        - task_key: aggregate_job_prospects
          spark_python_task:
            python_file: transform/transformations/aggregate_job_prospects.py
        # - task_key: clean_job_prospects
        #   depends_on:
        #     - task_key: extract_job_prospects
        #   notebook_task:
        #     notebook_path: load/transformations/clean_job_prospects.ipynb
        # - task_key: top_job_popularity
        #   depends_on:
        #     - task_key: clean_job_prospects
        #   notebook_task:
        #     notebook_path: top_job_popularity/transformations/top_job_popularity.ipynb
        # - task_key: job_description_features
        #   depends_on:
        #     - task_key: clean_job_prospects
        #   notebook_task:
        #     notebook_path: ../resources/job_description_features.py

        # - task_key: predict_salary_task
        #   depends_on:
        #     - task_key: job_description_features
        #   environment_key: default
        #   python_wheel_task:
        #     package_name: deltabricks
        #     entry_point: main

      environments:
        - environment_key: default
          spec:
            environment_version: "2"
            dependencies:
              - ../dist/*.whl

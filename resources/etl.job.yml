# The main job for deltabricks.
resources:
  jobs:
    deltabricks_etl_job:
      name: deltabricks_etl_job
      trigger:
        periodic:
          interval: 1
          unit: DAYS
      #email_notifications:
      #  on_failure:
      #    - khangnghiem@gmail.com

      tasks:
        - task_key: extract_job_prospects
          spark_python_task:
            python_file: extract/transformations/extract_job_prospects.py
        - task_key: clean_job_prospects
          depends_on:
            - task_key: extract_job_prospects
          notebook_task:
            notebook_path: load/transformations/clean_job_prospects.ipynb
        - task_key: top_job_popularity
          depends_on:
            - task_key: clean_job_prospects
          notebook_task:
            notebook_path: top_job_popularity/transformations/top_job_popularity.ipynb
        - task_key: job_description_features
          depends_on:
            - task_key: clean_job_prospects
          notebook_task:
            notebook_path: ../resources/job_description_features.py

        # - task_key: predict_salary_task
        #   depends_on:
        #     - task_key: job_description_features
        #   environment_key: default
        #   python_wheel_task:
        #     package_name: deltabricks
        #     entry_point: main

      environments:
        - environment_key: default
          # Full documentation of this spec can be found at:
          # https://docs.databricks.com/api/workspace/jobs/create#environments-spec
          spec:
            environment_version: "2"
            dependencies:
              - ../dist/*.whl

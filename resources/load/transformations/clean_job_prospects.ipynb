{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9782a30-3687-4956-9211-6ee48ca0c29a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762a030b-db21-471c-9364-9bf9580dfd37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_job_1900_bronze():\n",
    "    bronze = (\n",
    "        spark.read.option(\"multiline\", \"true\")\n",
    "        .format(\"json\")\n",
    "        .load(\"/Volumes/dev/job_prospects/job_1900_bronze\")\n",
    "    )\n",
    "    return bronze\n",
    "\n",
    "bronze = get_job_1900_bronze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c523f5c-06db-4546-b4a8-57c173cb65be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_number(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"^\\s*\\d+(\\.\\d+)?\\s*[kK]\"),\n",
    "            (F.regexp_extract(col, r\"(\\d+(\\.\\d+)?)\", 1).cast(\"double\") * 1000).cast(\n",
    "                \"int\"\n",
    "            ),\n",
    "        )\n",
    "        .when(F.col(col).rlike(r\"\\d+\"), F.regexp_extract(col, r\"(\\d+)\", 1).cast(\"int\"))\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_min_salary(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(F.lower(F.trim(F.col(col))) == \"thoả thuận\", None)\n",
    "        .when(F.col(col).rlike(r\"(?i)^t[ơo]i\\s*|^tới\\s*\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)trên\\s*([0-9]+(?:[.,][0-9]+)?)\\s*([^\\d\\s-]+)\"),\n",
    "            F.concat(\n",
    "                F.regexp_extract(col, r\"(?i)trên\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                F.lit(\" \"),\n",
    "                F.regexp_extract(\n",
    "                    col, r\"(?i)trên\\s*[0-9]+(?:[.,][0-9]+)?\\s*([^\\d\\s-]+)\", 1\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(\n",
    "                r\"^\\s*([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\\s*([^\\d\\s-]+)\"\n",
    "            ),\n",
    "            F.concat(\n",
    "                F.regexp_extract(col, r\"^\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                F.lit(\" \"),\n",
    "                F.regexp_extract(\n",
    "                    col,\n",
    "                    r\"^\\s*[0-9]+(?:[.,][0-9]+)?\\s*-\\s*[0-9]+(?:[.,][0-9]+)?\\s*([^\\d\\s-]+)\",\n",
    "                    1,\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        .otherwise(\n",
    "            F.trim(\n",
    "                F.concat(\n",
    "                    F.regexp_extract(col, r\"^\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                    F.lit(\" \"),\n",
    "                    F.regexp_extract(\n",
    "                        col, r\"^\\s*[0-9]+(?:[.,][0-9]+)?\\s*([^\\d\\s-]+)\", 1\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_max_salary(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(F.lower(F.trim(F.col(col))) == \"thoả thuận\", None)\n",
    "        .when(F.col(col).rlike(r\"(?i)^trên\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)^t[ơo]i\\s*([0-9]+(?:[.,][0-9]+)?)\\s*(triệu|usd)\"),\n",
    "            F.concat(\n",
    "                F.regexp_extract(col, r\"(?i)^t[ơo]i\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                F.lit(\" \"),\n",
    "                F.regexp_extract(\n",
    "                    col, r\"(?i)^t[ơo]i\\s*[0-9]+(?:[.,][0-9]+)?\\s*(triệu|usd)\", 1\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(\n",
    "                r\"^\\s*([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\\s*([^\\d\\s-]+)\"\n",
    "            ),\n",
    "            F.concat(\n",
    "                F.regexp_extract(\n",
    "                    col, r\"^\\s*([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\", 2\n",
    "                ),\n",
    "                F.lit(\" \"),\n",
    "                F.regexp_extract(\n",
    "                    col,\n",
    "                    r\"^\\s*[0-9]+(?:[.,][0-9]+)?\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\\s*([^\\d\\s-]+)\",\n",
    "                    2,\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        .otherwise(\n",
    "            F.trim(\n",
    "                F.concat(\n",
    "                    F.regexp_extract(col, r\"([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                    F.lit(\" \"),\n",
    "                    F.regexp_extract(col, r\"([0-9]+(?:[.,][0-9]+)?)\\s*([^\\d\\s-]+)\", 2),\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def convert_to_usd(col):\n",
    "    return (\n",
    "        F.when(\n",
    "            F.col(col).rlike(r\"(?i)([0-9]+(?:[.,][0-9]+)?)\\s*triệu\"),\n",
    "            (\n",
    "                (\n",
    "                    F.regexp_replace(\n",
    "                        F.regexp_extract(F.col(col), r\"([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                        \",\",\n",
    "                        \".\",\n",
    "                    ).cast(\"double\")\n",
    "                    * 1_000_000\n",
    "                )\n",
    "                * 0.000038\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)([0-9]+(?:[.,][0-9]+)?)\\s*usd\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(F.col(col), r\"([0-9]+(?:[.,][0-9]+)?)\", 1), \",\", \".\"\n",
    "            )\n",
    "            .cast(\"double\")\n",
    "            .cast(\"int\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_float(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"^\\s*-?\\d+([.,]\\d+)?\\s*$\"),\n",
    "            F.regexp_replace(F.col(col), \",\", \".\").cast(\"double\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_min_experience(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(F.lower(F.trim(F.col(col))) == \"không yêu cầu\", F.lit(0))\n",
    "        .when(F.col(col).rlike(r\"(?i)^t[ơo]i\\s*[0-9]+(?:[.,][0-9]+)?\\s*năm\"), F.lit(0))\n",
    "        .when(F.col(col).rlike(r\"(?i)^t[ơo]i\\s*năm\"), F.lit(0))\n",
    "        .when(F.col(col).rlike(r\"(?i)^tới\\s*[0-9]+(?:[.,][0-9]+)?\\s*năm\"), F.lit(0))\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)^trên\\s*([0-9]+(?:[.,][0-9]+)?)\\s*năm\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(col, r\"(?i)^trên\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                \",\",\n",
    "                \".\",\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(\n",
    "                r\"([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\\s*năm\"\n",
    "            ),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(\n",
    "                    col, r\"([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\", 1\n",
    "                ),\n",
    "                \",\",\n",
    "                \".\",\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"([0-9]+(?:[.,][0-9]+)?)\\s*năm\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(col, r\"([0-9]+(?:[.,][0-9]+)?)\\s*năm\", 1), \",\", \".\"\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    ).cast(\"int\")\n",
    "\n",
    "\n",
    "def parse_max_experience(col):\n",
    "    return (\n",
    "        F.when(F.col(col).isNull() | (F.trim(F.col(col)) == \"\"), None)\n",
    "        .when(F.lower(F.trim(F.col(col))) == \"không yêu cầu\", None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)^t[ơo]i\\s*[0-9]+(?:[.,][0-9]+)?\\s*năm\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(col, r\"(?i)^t[ơo]i\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                \",\",\n",
    "                \".\",\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(F.col(col).rlike(r\"(?i)^t[ơo]i\\s*năm\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"(?i)^tới\\s*[0-9]+(?:[.,][0-9]+)?\\s*năm\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(col, r\"(?i)^tới\\s*([0-9]+(?:[.,][0-9]+)?)\", 1),\n",
    "                \",\",\n",
    "                \".\",\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(F.col(col).rlike(r\"(?i)^trên\\s*([0-9]+(?:[.,][0-9]+)?)\\s*năm\"), None)\n",
    "        .when(\n",
    "            F.col(col).rlike(\n",
    "                r\"([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\\s*năm\"\n",
    "            ),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(\n",
    "                    col, r\"([0-9]+(?:[.,][0-9]+)?)\\s*-\\s*([0-9]+(?:[.,][0-9]+)?)\", 2\n",
    "                ),\n",
    "                \",\",\n",
    "                \".\",\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .when(\n",
    "            F.col(col).rlike(r\"([0-9]+(?:[.,][0-9]+)?)\\s*năm\"),\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(col, r\"([0-9]+(?:[.,][0-9]+)?)\\s*năm\", 1), \",\", \".\"\n",
    "            ).cast(\"int\"),\n",
    "        )\n",
    "        .otherwise(None)\n",
    "    ).cast(\"int\")\n",
    "\n",
    "\n",
    "def parse_area(col):\n",
    "    cleaned = F.regexp_replace(F.col(col), r\"Địa điểm làm việc:\\s*\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"\\s*-\\s*Việc làm tại\\s*\", \"|\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)Việc làm tại\\s*\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"\\s*-\\s*\", \"|\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"375 Đường Ngọc Hồi|Thị Trấn Văn Điển|Huyện Thanh Trì|TP Hà Nội\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(\\[\\\")|(\\\"\\])|(\\\")\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"^\\s*\\d+[^\\,]*,\\s*\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\":\", \"\")\n",
    "    for i in range(1, 18):\n",
    "        cleaned = F.regexp_replace(\n",
    "            cleaned,\n",
    "            r\"(?i)^\\s*((\\d+)|(địa chỉ)|(ấp)|(huyện)|(quận)|(xã)|(phường)|(p\\.)|(q\\.)|(khóm)|(thị tr)|(tại hộ)|(phố)|(đài)|(uỷ)|(Ủy)|(UBND)|(Hđnd)|(tại\\str)|(km)|(bệnh viện)|(hội trường)|(dự kiến)|(văn phòng)|(bộ phận)|(cảng)|(trường)|(nhà)|(quốc lộ)|(cơ sở)|(trụ sở)|(học v)|(\\(tầng)|(thôn)|(P\\sH)|(thị xã)|(chung cư)|(ố \\d)|(tổ)|(toà)|(Tòa)|(nộp)|(tại phòng)|(tại bệnh)|(tại tầ)|(trung tâm)|(công ty)|(chi nhánh)|(khoa y)|(Đhqg)|(P2809)|(tt)|(ban bồi)|(lầu)|(khối)|(số)|(ban\\stổ)|(khoa\\sdu)|(Số)|(Số)|(khu)|(ngõ)|(tiểu khu)|(\\+)|(kp)|(đường)|(phòng)|(trường)|(tân hưng,\\sq7)|(đại học)|(thành phố Thủ Đức)|(GÒ VẤP)|(chi cục)|(thị xã)|(nhận phiếu)|(trong giờ)|(đại học)|(khoa tài)|(trường)|(điện thoại)|(địa chỉ)|(sở y tế)|(sở văn hoá)|(tại văn)|(khoa lu)|(tạp chí)|(Tầng)|(tháp)|(xóm)|(Các ứng))[^,]*,\\s*\",\n",
    "            \"\",\n",
    "        )\n",
    "    cleaned = F.regexp_replace(cleaned, r\"thành phố Hà Nội\\.\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)tỉnh Kon Tum*tỉnh Kon Tum\", \"Kon Tum\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)(TP. Hồ Chí Minh)|(TPHCM)|(TP.HCM)|(TP. HCM)|(TP\\.Hồ Chí Minh)|(HCM)|(Hồ Chí MinhC)\", \"Hồ Chí Minh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)tỉnh\\s\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)thành phố\\s([^,]+), \\1\", r\"\\1\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)\\s*(Đắk Nông).*\\1\", r\"\\1\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Trường Đại học Việt Nhật .* Hà Nội \\(ĐHQGHN\\)\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"\\s*\\([^\\)]*\\)\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Dự kiến tại Trường THPT số 2 Lào Cai\", \"Lào Cai\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"thành phố Hà Nội và cơ sở 2 tại xã Tân Minh, huyện Sóc Sơn, Hà Nội\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Nhà số 27 – Đường 800A|Nghĩa Đô – Cầu giấy\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"thành phố Hà Nội hoặc gửi theo đường bưu chính theo địa chỉ trên.\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"    dự kiến tại trường THCS Trần Văn Ơn, số 03 Phạm Phú Thứ, phường Hạ Lý, quận Hồng Bàng, thành phố Hải Phòng.\", \"Hải Phòng\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Nộp trực tiếp tại Phòng Tổ chức – Hành chính, Trung tâm Kiểm soát bệnh tật Quảng Trị.\", \"Quảng Trị\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)(TP. Hồ Chí Minh)|(TPHCM)|(TP.HCM)|(TP. HCM)|(TP\\.Hồ Chí Minh)|(HCM)|(Hồ Chí MinhC)\", \"Hồ Chí Minh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)Tầng 9\\|Khu trung tâm hành chính Số 36\\|Trần Phú\\|Phường 4\\|TP Đà Lạt\\.\", \"Đà Lạt\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)^quận \\d$\", \"Hồ Chí Minh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)(tp\\.)|(TP\\s)\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Hồ Chí Minh – Điện thoại 028 3965 0197\\.\", \"Hồ Chí Minh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Quận 5\\|Hồ Chí Minh\", \"Hồ Chí Minh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)(tp\\.)|(TP\\s)|(thành\\sphố\\s)\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(Quảng Ninh hoặc gửi theo đường bưu chính\\.)|(Đinh Tiên Hoàng, phường Quang Trung, Uông Bí, Quảng Ninh)\", \"Quảng Ninh\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"Tân An, Long An; từ ngày 01/3/2025 nhận hồ sơ tại trụ sở mới – Tuyến tránh Quốc lộ 1A, phường 4, Tân An, Long An\\.\", \"Long An\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)TP[^,]*Bắc Kạn, Bắc Kạn.\", \"Bắc Kạn\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)TP\\r\\n(Bắc Kạn), \\1\\)\", r\"\\1\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)Số 246\\|lộ 943\\|Phường Mỹ Hòa\\| Long Xuyên\\|An Giang\", \"An Giang\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)\\+ Số 48 Tô Hiệu\\|Hà Đông\\|Hà Nội.*Hà Nội\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)169 Nguyễn Ngọc Vũ\\|Trung Hòa\\|Cầu Giấy\\|Hà Nội\", \"Hà Nội\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(\\)\\.)|(\\.)\", \"\")\n",
    "    cleaned = F.regexp_replace(cleaned, r\"(?i)viện\\s([^,]+)\", \"\")\n",
    "    return F.trim(cleaned)\n",
    "\n",
    "\n",
    "\n",
    "def parse_employment_type(col):\n",
    "    return F.array_distinct(\n",
    "        F.transform(F.split(F.col(col), r\"\\s*,\\s*|\\s*;\\s*\"), lambda x: F.trim(x))\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_gender(col):\n",
    "    return F.when(\n",
    "        F.lower(F.trim(F.col(col))).isin(\"nam\", \"nữ\"),\n",
    "        F.initcap(F.lower(F.trim(F.col(col)))),\n",
    "    ).otherwise(\"Không yêu cầu\")\n",
    "\n",
    "\n",
    "def parse_company_size(col):\n",
    "    return F.when(F.col(col) == \"__\", None).otherwise(F.col(col))\n",
    "\n",
    "\n",
    "df = bronze.withColumns(\n",
    "    {\n",
    "        \"id\": F.monotonically_increasing_id(),\n",
    "        \"timestamp\": F.to_date(\"timestamp\"),\n",
    "        \"number_of_reviews\": parse_number(\"number_of_reviews\"),\n",
    "        \"number_of_jobs\": parse_number(\"number_of_jobs\"),\n",
    "        \"views\": parse_number(\"views\"),\n",
    "        \"salary_low\": parse_min_salary(\"salary\"),\n",
    "        \"salary_high\": parse_max_salary(\"salary\"),\n",
    "        \"employment_type\": parse_employment_type(\"employment_type\"),\n",
    "        \"posted_at\": F.to_date(F.col(\"posted_at\"), \"dd/MM/yyyy\"),\n",
    "        \"quantity\": parse_number(\"quantity\"),\n",
    "        \"application_deadline\": F.to_date(\n",
    "            F.col(\"application_deadline\"), \"dd/MM/yyyy\"\n",
    "        ),\n",
    "        \"minimum_experience\": parse_min_experience(\"experience\"),\n",
    "        \"maximum_experience\": parse_max_experience(\"experience\"),\n",
    "        \"gender\": parse_gender(\"gender\"),\n",
    "        # gender\n",
    "        # \"job_description\": F.when(\n",
    "        #     F.col(\"job_description\").isNotNull(),\n",
    "        #     F.expr(\"concat_ws('\\n', job_description)\")\n",
    "        # ).otherwise(None),\n",
    "        \"company_size\": parse_company_size(\"company_size\"),\n",
    "        \"company_rating\": parse_float(\"company_rating\"),\n",
    "        \"area\": parse_area(\"area\"),\n",
    "    }\n",
    ")\n",
    "df = df.withColumns(\n",
    "    {\n",
    "        \"quantity\": F.when(F.col(\"quantity\") > 5, F.lit(5)).otherwise(\n",
    "            F.col(\"quantity\")\n",
    "        ),\n",
    "        \"salary_low\": convert_to_usd(\"salary_low\"),\n",
    "        \"salary_high\": convert_to_usd(\"salary_high\"),\n",
    "    }\n",
    ")\n",
    "# display(df.select(F.explode(\"area\").alias(\"area\")).distinct())\n",
    "# display(df.select(\"area\").distinct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f8757b96-b901-49cf-820c-ea18b5c6cc87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "area_list = [\n",
    "    \"Cao Bằng\",\n",
    "    \"Sơn La\",\n",
    "    \"Lai Châu\",\n",
    "    \"Lạng Sơn\",\n",
    "    \"Tuyên Quang\",\n",
    "    \"Lào Cai\",\n",
    "    \"Thái Nguyên\",\n",
    "    \"Điện Biên\",\n",
    "    \"Phú Thọ\",\n",
    "    \"Bắc Ninh\",\n",
    "    \"Hà Nội\",\n",
    "    \"Quảng Ninh\",\n",
    "    \"Hải Phòng\",\n",
    "    \"Hưng Yên\",\n",
    "    \"Ninh Bình\",\n",
    "    \"Thanh Hóa\",\n",
    "    \"Nghệ An\",\n",
    "    \"Hà Tĩnh\",\n",
    "    \"Quảng Trị\",\n",
    "    \"Huế\",\n",
    "    \"Đà Nẵng\",\n",
    "    \"Quảng Ngãi\",\n",
    "    \"Gia Lai\",\n",
    "    \"Đắk Lắk\",\n",
    "    \"Khánh Hòa\",\n",
    "    \"Lâm Đồng\",\n",
    "    \"Đồng Nai\",\n",
    "    \"Thành phố Hồ Chí Minh\",\n",
    "    \"Tây Ninh\",\n",
    "    \"Đồng Tháp\",\n",
    "    \"Vĩnh Long\",\n",
    "    \"Cần Thơ\",\n",
    "    \"An Giang\",\n",
    "    \"Cà Mau\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87bf0914-0471-436a-8b3e-6d7b43e3a195",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df_view\")\n",
    "area_list_str = json.dumps(area_list)\n",
    "\n",
    "classified_area_df = spark.sql(\n",
    "    f\"\"\"\n",
    "    SELECT *,\n",
    "        from_json(\n",
    "            ai_query(\n",
    "                'databricks-meta-llama-3-3-70b-instruct',\n",
    "                'Given the following area names as string separated by \",\" or \"|\", classify each into one or more of the following valid areas:\\n {area_list_str}\\nReturn a list of matched area(s) for each input in only an JSON array format, no comments whatsoever. Input:\\n' || area || \"For example, if the input is 'Hà Nội,quận 1, TP. HCM|Hải Phòng', the output should be a JSON format: ['Hà Nội', 'TP. HCM', 'Hải Phòng']\"\n",
    "            ),\n",
    "            'ARRAY<STRING>'\n",
    "        ) AS area_classified\n",
    "    FROM df_view\n",
    "    \"\"\"\n",
    ")\n",
    "silver.withColumn(\n",
    "    \"area\", classified_area_df[\"area_classified\"]\n",
    ").drop(\"area_classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e7de1d4-39db-4872-a0eb-9f0d6a11b1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"dev.job_prospects.job_1900_silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2dcf7a3-94bc-41e5-bd8b-0e705ef28b8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test cases for parse_number\n",
    "test_data = [\n",
    "    (\"100\", 100),\n",
    "    (\"2k\", 2000),\n",
    "    (\"3.5K\", 3500),\n",
    "    (\" 7 K \", 7000),\n",
    "    (\"12\", 12),\n",
    "    (\"0\", 0),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "    (\"abc\", None),\n",
    "    (\"1.2k\", 1200),\n",
    "    (\"999\", 999),\n",
    "    (\"5.7k\", 5700),\n",
    "]\n",
    "\n",
    "test_df = spark.createDataFrame(test_data, [\"input\", \"expected\"])\n",
    "result_df = test_df.withColumn(\"parsed\", parse_number(\"input\"))\n",
    "\n",
    "mismatches = result_df.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert mismatches.count() == 0, \"parse_number failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_min_salary\n",
    "min_salary_data = [\n",
    "    (\"10 triệu\", \"10 triệu\"),\n",
    "    (\"15 usd\", \"15 usd\"),\n",
    "    (\"Trên 20 triệu\", \"20 triệu\"),\n",
    "    (\"5-10 triệu\", \"5 triệu\"),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "    (\"thoả thuận\", None),\n",
    "    (\"Tới 30 triệu\", None),\n",
    "]\n",
    "min_salary_df = spark.createDataFrame(min_salary_data, [\"input\", \"expected\"])\n",
    "min_salary_result = min_salary_df.withColumn(\"parsed\", parse_min_salary(\"input\"))\n",
    "min_salary_mismatches = min_salary_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert min_salary_mismatches.count() == 0, \"parse_min_salary failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_max_salary\n",
    "max_salary_data = [\n",
    "    (\"10 triệu\", \"10 triệu\"),\n",
    "    (\"15 usd\", \"15 usd\"),\n",
    "    (\"Tới 20 triệu\", \"20 triệu\"),\n",
    "    (\"5-10 triệu\", \"10 triệu\"),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "    (\"thoả thuận\", None),\n",
    "    (\"Trên 30 triệu\", None),\n",
    "]\n",
    "max_salary_df = spark.createDataFrame(max_salary_data, [\"input\", \"expected\"])\n",
    "max_salary_result = max_salary_df.withColumn(\"parsed\", parse_max_salary(\"input\"))\n",
    "max_salary_mismatches = max_salary_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert max_salary_mismatches.count() == 0, \"parse_max_salary failed for some test cases\"\n",
    "\n",
    "# Test cases for convert_to_usd\n",
    "usd_data = [\n",
    "    (\"10 triệu\", int(10_000_000 * 0.000038)),\n",
    "    (\"15 usd\", 15),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "    (\"abc\", None),\n",
    "]\n",
    "usd_df = spark.createDataFrame(usd_data, [\"input\", \"expected\"])\n",
    "usd_result = usd_df.withColumn(\"parsed\", convert_to_usd(\"input\"))\n",
    "usd_mismatches = usd_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert usd_mismatches.count() == 0, \"convert_to_usd failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_float\n",
    "float_data = [\n",
    "    (\"4.5\", 4.5),\n",
    "    (\"3,2\", 3.2),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "    (\"abc\", None),\n",
    "]\n",
    "float_df = spark.createDataFrame(float_data, [\"input\", \"expected\"])\n",
    "float_result = float_df.withColumn(\"parsed\", parse_float(\"input\"))\n",
    "float_mismatches = float_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert float_mismatches.count() == 0, \"parse_float failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_min_experience\n",
    "min_exp_data = [\n",
    "    (\"2 năm\", 2),\n",
    "    (\"Không yêu cầu\", 0),\n",
    "    (\"Tới 5 năm\", 0),\n",
    "    (\"Trên 4 năm\", 4),\n",
    "    (\"1-3 năm\", 1),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "]\n",
    "min_exp_df = spark.createDataFrame(min_exp_data, [\"input\", \"expected\"])\n",
    "min_exp_result = min_exp_df.withColumn(\"parsed\", parse_min_experience(\"input\"))\n",
    "min_exp_mismatches = min_exp_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert min_exp_mismatches.count() == 0, \"parse_min_experience failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_max_experience\n",
    "max_exp_data = [\n",
    "    (\"2 năm\", 2),\n",
    "    (\"Không yêu cầu\", None),\n",
    "    (\"Tới 5 năm\", 5),\n",
    "    (\"Trên 4 năm\", None),\n",
    "    (\"1-3 năm\", 3),\n",
    "    (\"\", None),\n",
    "    (None, None),\n",
    "]\n",
    "max_exp_df = spark.createDataFrame(max_exp_data, [\"input\", \"expected\"])\n",
    "max_exp_result = max_exp_df.withColumn(\"parsed\", parse_max_experience(\"input\"))\n",
    "max_exp_mismatches = max_exp_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert max_exp_mismatches.count() == 0, \"parse_max_experience failed for some test cases\"\n",
    "\n",
    "# Test parse_employment_type\n",
    "test_df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"Full-time, Part-time\", [\"Full-time\", \"Part-time\"]),\n",
    "        (\"Full-time ,Part-time\", [\"Full-time\", \"Part-time\"]),\n",
    "        (\"Contract ; Freelance\", [\"Contract\", \"Freelance\"]),\n",
    "        (\"Internship\", [\"Internship\"]),\n",
    "        (\"Full-time, Full-time\", [\"Full-time\"]),\n",
    "        (\"\", [\"\"]),       # empty → [\"\"]\n",
    "        (None, []),       # None → []\n",
    "    ],\n",
    "    [\"raw\", \"expected\"]\n",
    ")\n",
    "\n",
    "result_df = test_df.select(\n",
    "    \"raw\",\n",
    "    \"expected\",\n",
    "    F.coalesce(parse_employment_type(\"raw\"), F.array()).alias(\"parsed\")\n",
    ")\n",
    "\n",
    "assert result_df.filter(F.col(\"parsed\") != F.col(\"expected\")).count() == 0\n",
    "\n",
    "# Test cases for parse_gender\n",
    "gender_data = [\n",
    "    (\"Nam\", \"Nam\"),\n",
    "    (\"Nữ\", \"Nữ\"),\n",
    "    (\"nam\", \"Nam\"),\n",
    "    (\"nữ\", \"Nữ\"),\n",
    "    (\"Không yêu cầu\", \"Không yêu cầu\"),\n",
    "    (\"\", \"Không yêu cầu\"),\n",
    "    (None, \"Không yêu cầu\"),\n",
    "    (\"Other\", \"Không yêu cầu\"),\n",
    "]\n",
    "gender_df = spark.createDataFrame(gender_data, [\"input\", \"expected\"])\n",
    "gender_result = gender_df.withColumn(\"parsed\", parse_gender(\"input\"))\n",
    "gender_mismatches = gender_result.filter(~(F.col(\"parsed\") == F.col(\"expected\")))\n",
    "assert gender_mismatches.count() == 0, \"parse_gender failed for some test cases\"\n",
    "\n",
    "# Test cases for parse_company_size\n",
    "company_size_data = [\n",
    "    (\"__\", None),\n",
    "    (\"100-200\", \"100-200\"),\n",
    "    (\"\", \"\"),\n",
    "    (None, None),\n",
    "]\n",
    "company_size_df = spark.createDataFrame(company_size_data, [\"input\", \"expected\"])\n",
    "company_size_result = company_size_df.withColumn(\"parsed\", parse_company_size(\"input\"))\n",
    "company_size_mismatches = company_size_result.filter(~(F.col(\"parsed\").eqNullSafe(F.col(\"expected\"))))\n",
    "assert company_size_mismatches.count() == 0, \"parse_company_size failed for some test cases\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clean_job_prospects",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
